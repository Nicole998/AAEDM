{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3f6e62",
   "metadata": {
    "scrolled": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import torch, math, time, argparse, os\n",
    "import random, dataset, utils, losses, net\n",
    "import numpy as np\n",
    "from dataset.Inshop import Inshop_Dataset\n",
    "from net.resnet import *\n",
    "from net.googlenet import *\n",
    "from net.bn_inception import *\n",
    "from net.alexnet import *\n",
    "from net.densenet import *\n",
    "from dataset import sampler\n",
    "from torch.utils.data.sampler import BatchSampler\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from tqdm import *\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "#参数设置\n",
    "args_emb_size=512\n",
    "args_sz_batch=90\n",
    "args_nb_workers=0\n",
    "args_gpu_id=1\n",
    "args_lr=1e-4\n",
    "args_nb_epochs=10\n",
    "args_bn_freeze=1\n",
    "args_gpu_id=0\n",
    "args_warm=1\n",
    "args_LOG_DIR='../logs'\n",
    "args_dataset='kongyu'\n",
    "args_model='bn_inception'\n",
    "# args_loss='Rank_List_Proxy_Anchor2'\n",
    "args_loss='New_loss'\n",
    "args_sz_embedding=512\n",
    "args_alpha=32\n",
    "args_mrg=0.4\n",
    "args_optimizer='adamw'\n",
    "args_remark=''\n",
    "args_IPC=''\n",
    "args_l2_norm=1\n",
    "# args_bn_freeze=1\n",
    "args_weight_decay=1e-4\n",
    "args_lr_decay_step=10\n",
    "args_lr_decay_gamma=0.5\n",
    "args_evald='acc1'\n",
    "\n",
    "\n",
    "\n",
    "#设置随机种子便于复现\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed) # set random seed for all gpus\n",
    "\n",
    "\n",
    "\n",
    "torch.cuda.set_device(1)\n",
    "\n",
    "# Directory for Log\n",
    "LOG_DIR = args_LOG_DIR + '/logs_{}/{}_{}_embedding{}_alpha{}_mrg{}_{}_lr{}_batch{}{}'.format(args_dataset, args_model, args_loss, args_sz_embedding, args_alpha, \n",
    "                                                                                            args_mrg, args_optimizer, args_lr, args_sz_batch, args_remark)\n",
    "\n",
    "# os.chdir('../data/')\n",
    "data_root = os.getcwd()\n",
    "# Dataset Loader and Sampler\n",
    "if args_dataset != 'Inshop':\n",
    "    trn_dataset = dataset.load(\n",
    "            name = args_dataset,\n",
    "            root = data_root,\n",
    "            mode = 'train',\n",
    "            transform = dataset.utils.make_transform(\n",
    "                is_train = True, \n",
    "                is_inception = (args_model == 'bn_inception')\n",
    "            ))\n",
    "else:\n",
    "    trn_dataset = Inshop_Dataset(\n",
    "            root = data_root,\n",
    "            mode = 'train',\n",
    "            transform = dataset.utils.make_transform(\n",
    "                is_train = True, \n",
    "                is_inception = (args_model == 'bn_inception')\n",
    "            ))\n",
    "\n",
    "if args_IPC:\n",
    "    balanced_sampler = sampler.BalancedSampler(trn_dataset, batch_size=args_sz_batch, images_per_class = args_IPC)\n",
    "    batch_sampler = BatchSampler(balanced_sampler, batch_size = args_sz_batch, drop_last = True)\n",
    "    dl_tr = torch.utils.data.DataLoader(\n",
    "        trn_dataset,\n",
    "        num_workers = args_nb_workers,\n",
    "        pin_memory = True,\n",
    "        batch_sampler = batch_sampler\n",
    "    )\n",
    "    print('Balanced Sampling')\n",
    "    \n",
    "else:\n",
    "    dl_tr = torch.utils.data.DataLoader(\n",
    "        trn_dataset,\n",
    "        batch_size = args_sz_batch,\n",
    "        shuffle = True,\n",
    "        num_workers = args_nb_workers,\n",
    "        drop_last = True,\n",
    "        pin_memory = True\n",
    "    )\n",
    "    print('Random Sampling')\n",
    "\n",
    "if args_dataset != 'Inshop':\n",
    "    ev_dataset = dataset.load(\n",
    "            name = args_dataset,\n",
    "            root = data_root,\n",
    "            mode = 'eval',\n",
    "            transform = dataset.utils.make_transform(\n",
    "                is_train = False, \n",
    "                is_inception = (args_model == 'bn_inception')\n",
    "            ))\n",
    "\n",
    "    dl_ev = torch.utils.data.DataLoader(\n",
    "        ev_dataset,\n",
    "        batch_size = args_sz_batch,\n",
    "        shuffle = False,\n",
    "        num_workers = args_nb_workers,\n",
    "        pin_memory = True\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    query_dataset = Inshop_Dataset(\n",
    "            root = data_root,\n",
    "            mode = 'query',\n",
    "            transform = dataset.utils.make_transform(\n",
    "                is_train = False, \n",
    "                is_inception = (args_model == 'bn_inception')\n",
    "    ))\n",
    "    \n",
    "    dl_query = torch.utils.data.DataLoader(\n",
    "        query_dataset,\n",
    "        batch_size = args_sz_batch,\n",
    "        shuffle = False,\n",
    "        num_workers = args_nb_workers,\n",
    "        pin_memory = True\n",
    "    )\n",
    "\n",
    "    gallery_dataset = Inshop_Dataset(\n",
    "            root = data_root,\n",
    "            mode = 'gallery',\n",
    "            transform = dataset.utils.make_transform(\n",
    "                is_train = False, \n",
    "                is_inception = (args_model == 'bn_inception')\n",
    "    ))\n",
    "    \n",
    "    dl_gallery = torch.utils.data.DataLoader(\n",
    "        gallery_dataset,\n",
    "        batch_size = args_sz_batch,\n",
    "        shuffle = False,\n",
    "        num_workers = args_nb_workers,\n",
    "        pin_memory = True\n",
    "    )\n",
    "\n",
    "nb_classes = 5\n",
    "\n",
    "# Backbone Model\n",
    "if args_model.find('googlenet')+1:\n",
    "    model = googlenet(embedding_size=args_sz_embedding, pretrained=True, is_norm=args_l2_norm, bn_freeze = args_bn_freeze)\n",
    "elif args_model.find('bn_inception')+1:\n",
    "    model = bn_inception(embedding_size=args_sz_embedding, pretrained=True, is_norm=args_l2_norm, bn_freeze = args_bn_freeze)\n",
    "elif args_model.find('resnet18')+1:\n",
    "    model = Resnet18(embedding_size=args_sz_embedding, pretrained=True, is_norm=args_l2_norm, bn_freeze = args_bn_freeze)\n",
    "elif args_model.find('resnet50')+1:\n",
    "    model = Resnet50(embedding_size=args_sz_embedding, pretrained=True, is_norm=args_l2_norm, bn_freeze = args_bn_freeze)\n",
    "elif args_model.find('resnet101')+1:\n",
    "    model = Resnet101(embedding_size=args_sz_embedding, pretrained=True, is_norm=args_l2_norm, bn_freeze = args_bn_freeze)\n",
    "elif args_model.find('alexnet')+1:\n",
    "    model = alexnet(embedding_size=args_sz_embedding, pretrained=True, is_norm=args_l2_norm, bn_freeze = args_bn_freeze)\n",
    "elif args_model.find('densenet121')+1:\n",
    "    model = Densenet121(embedding_size=args_sz_embedding, pretrained=True, is_norm=args_l2_norm, bn_freeze = args_bn_freeze)\n",
    "elif args_model.find('densenet161')+1:\n",
    "    model = Densenet161(embedding_size=args_sz_embedding, pretrained=True, is_norm=args_l2_norm, bn_freeze = args_bn_freeze)\n",
    "model = model.cuda()\n",
    "\n",
    "if args_gpu_id == -1:\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "# DML Losses\n",
    "if args_loss == 'Proxy_Anchor':\n",
    "    criterion = losses.Proxy_Anchor(nb_classes = nb_classes, sz_embed = args_sz_embedding, mrg = args_mrg, alpha = args_alpha).cuda()\n",
    "elif args_loss == 'Proxy_NCA':\n",
    "    criterion = losses.Proxy_NCA(nb_classes = nb_classes, sz_embed = args_sz_embedding).cuda()\n",
    "elif args_loss == 'MS':\n",
    "    criterion = losses.MultiSimilarityLoss().cuda()\n",
    "elif args_loss == 'Contrastive':\n",
    "    criterion = losses.ContrastiveLoss(mrg = args_mrg).cuda()\n",
    "elif args_loss == 'Triplet':\n",
    "    criterion = losses.TripletLoss(mrg = args_mrg).cuda()\n",
    "elif args_loss == 'NPair':\n",
    "    criterion = losses.NPairLoss().cuda()\n",
    "elif args_loss == 'Rank_List_Proxy_Anchor':\n",
    "    criterion = losses.Rank_List_Proxy_Anchor(nb_classes = nb_classes, sz_embed = args_sz_embedding).cuda()\n",
    "elif args_loss == 'Rank_List_Proxy_Anchor2':\n",
    "    criterion = losses.Rank_List_Proxy_Anchor2(nb_classes = nb_classes, sz_embed = args_sz_embedding).cuda()\n",
    "elif args_loss == 'DA_Rank_List_Proxy_Anchor':\n",
    "    criterion = losses.DA_Rank_List_Proxy_Anchor(nb_classes = nb_classes, sz_embed = args_sz_embedding).cuda()\n",
    "elif args_loss == 'EE_Rank_List_Proxy_Anchor':\n",
    "    criterion = losses.EE_Rank_List_Proxy_Anchor(nb_classes = nb_classes, sz_embed = args_sz_embedding).cuda()\n",
    "elif args_loss == 'New_loss':\n",
    "    criterion = losses.New_loss(nb_classes = nb_classes, sz_embed = args_sz_embedding).cuda()\n",
    "    \n",
    "\n",
    "# Train Parameters\n",
    "param_groups = [\n",
    "    {'params': list(set(model.parameters()).difference(set(model.model.embedding.parameters()))) if args_gpu_id != -1 else \n",
    "                 list(set(model.module.parameters()).difference(set(model.module.model.embedding.parameters())))},\n",
    "    {'params': model.model.embedding.parameters() if args_gpu_id != -1 else model.module.model.embedding.parameters(), 'lr':float(args_lr) * 1},\n",
    "]\n",
    "if args_loss == 'Proxy_Anchor':\n",
    "    param_groups.append({'params': criterion.proxies, 'lr':float(args_lr) * 100})\n",
    "elif args_loss == 'Rank_List_Proxy_Anchor':\n",
    "    param_groups.append({'params': criterion.proxies, 'lr': float(args_lr) * 100})\n",
    "elif args_loss == 'Rank_List_Proxy_Anchor2':\n",
    "    param_groups.append({'params': criterion.proxies, 'lr': float(args_lr) * 100})\n",
    "elif args_loss == 'New_loss':\n",
    "    param_groups.append({'params': criterion.proxies, 'lr': float(args_lr) * 100})\n",
    "elif args_loss == 'DA_Rank_List_Proxy_Anchor':\n",
    "    param_groups.append({'params': criterion.proxies, 'lr': float(args_lr) * 100})\n",
    "    param_groups.append({'params': criterion.alphac})\n",
    "elif args_loss == 'EE_Rank_List_Proxy_Anchor':\n",
    "    param_groups.append({'params': criterion.proxies, 'lr': float(args_lr) * 100})\n",
    "\n",
    "# Optimizer Setting\n",
    "if args_optimizer == 'sgd': \n",
    "    opt = torch.optim.SGD(param_groups, lr=float(args_lr), weight_decay = args_weight_decay, momentum = 0.9, nesterov=True)\n",
    "elif args_optimizer == 'adam': \n",
    "    opt = torch.optim.Adam(param_groups, lr=float(args_lr), weight_decay = args_weight_decay)\n",
    "elif args_optimizer == 'rmsprop':\n",
    "    opt = torch.optim.RMSprop(param_groups, lr=float(args_lr), alpha=0.9, weight_decay = args_weight_decay, momentum = 0.9)\n",
    "elif args_optimizer == 'adamw':\n",
    "    opt = torch.optim.AdamW(param_groups, lr=float(args_lr), weight_decay = args_weight_decay)\n",
    "\n",
    "#包装model和opt\n",
    "# model, opt = amp.initialize(model, opt, opt_level=\"O1\")\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=args_lr_decay_step, gamma = args_lr_decay_gamma)\n",
    "\n",
    "# print(\"Training parameters: {}\".format(vars(args)))\n",
    "print(\"Training for {} epochs.\".format(args_nb_epochs))\n",
    "losses_list = []\n",
    "acc_list = []\n",
    "best_recall=[0]\n",
    "best_acc = 0\n",
    "best_mae = 1\n",
    "best_f1 = 0\n",
    "best_epoch = 0\n",
    "start = time.time()\n",
    "print(\"start training\")\n",
    "for epoch in range(0, args_nb_epochs):\n",
    "    model.train()\n",
    "    bn_freeze = args_bn_freeze\n",
    "    if bn_freeze:\n",
    "        modules = model.model.modules() if args_gpu_id != -1 else model.module.model.modules()\n",
    "        for m in modules: \n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.eval()\n",
    "\n",
    "    losses_per_epoch = []\n",
    "    acc = 0.\n",
    "    mae = 0.\n",
    "    f1 = 0.\n",
    "    \n",
    "    # Warmup: Train only new params, helps stabilize learning.\n",
    "    if args_warm > 0:\n",
    "        if args_gpu_id != -1:\n",
    "            unfreeze_model_param = list(model.model.embedding.parameters()) + list(criterion.parameters())\n",
    "        else:\n",
    "            unfreeze_model_param = list(model.module.model.embedding.parameters()) + list(criterion.parameters())\n",
    "\n",
    "        if epoch == 0:\n",
    "            for param in list(set(model.parameters()).difference(set(unfreeze_model_param))):\n",
    "                param.requires_grad = False\n",
    "        if epoch == args_warm:\n",
    "            for param in list(set(model.parameters()).difference(set(unfreeze_model_param))):\n",
    "                param.requires_grad = True\n",
    "\n",
    "    pbar = tqdm(enumerate(dl_tr))\n",
    "\n",
    "    for batch_idx, (x, y) in pbar:\n",
    "        m = model(x.squeeze().cuda())\n",
    "        if args_loss == 'DA_Rank_List_Proxy_Anchor':\n",
    "        \tfeature = model.feature\n",
    "        \tloss = criterion(m, y.squeeze().cuda(),feature)\n",
    "        else:\n",
    "        \tloss = criterion(m, y.squeeze().cuda())\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        #混合精度\n",
    "        # with amp.scale_loss(loss, opt) as scaled_loss:\n",
    "        #     scaled_loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_value_(model.parameters(), 10)\n",
    "        if args_loss == 'Proxy_Anchor':\n",
    "            torch.nn.utils.clip_grad_value_(criterion.parameters(), 10)\n",
    "        elif args_loss == 'Rank_List_Proxy_Anchor2':\n",
    "            torch.nn.utils.clip_grad_value_(criterion.parameters(), 10)\n",
    "        elif args_loss == 'DA_Rank_List_Proxy_Anchor':\n",
    "            torch.nn.utils.clip_grad_value_(criterion.parameters(), 10)\n",
    "        elif args_loss == 'EE_Rank_List_Proxy_Anchor':\n",
    "            torch.nn.utils.clip_grad_value_(criterion.parameters(), 10)\n",
    "        elif args_loss == 'New_loss':\n",
    "            torch.nn.utils.clip_grad_value_(criterion.parameters(), 10)\n",
    "\n",
    "        losses_per_epoch.append(loss.data.cpu().numpy())\n",
    "        opt.step()\n",
    "\n",
    "        \n",
    "    losses_list.append(np.mean(losses_per_epoch))\n",
    "    scheduler.step()\n",
    "    \n",
    "    if(epoch >= 0):\n",
    "        with torch.no_grad():\n",
    "            # print(\"**Evaluating...**\")\n",
    "            if args_evald == 'recallk':\n",
    "                Recalls = utils.evaluate_cos(model, dl_ev)\n",
    "            elif args_evald == 'acc':\n",
    "                acc = utils.evaluate_acc(model, dl_ev)\n",
    "                print(\"New_epoch:{e},Acc={acc}\".format(e=epoch+1,acc=acc))\n",
    "                acc_list.append(acc)\n",
    "            elif args_evald == 'mae':\n",
    "                mae = utils.evaluate_mae(model, dl_ev)\n",
    "            else:\n",
    "                f1 = utils.evaluate_small(model, dl_ev)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1bee109f",
   "metadata": {},
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eeb339f7",
   "metadata": {},
   "source": [
    "f1=np.array(f1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2f6e6d2",
   "metadata": {},
   "source": [
    "len(f1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2bc820b4",
   "metadata": {},
   "source": [
    "Counter(f1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "77cc59eb",
   "metadata": {},
   "source": [
    "torch.pow(torch.tensor(1),torch.tensor(1))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bdfc82ab",
   "metadata": {},
   "source": [
    "torch.exp(torch.tensor([0.1+1,0.2+1,0.3+1]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "14b4dc91",
   "metadata": {},
   "source": [
    "torch.log10(torch.tensor(100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LINGHUI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "fbb8111bdc8c3efce58afc4ae0edf16fe7597b1f05a0acc642e6d53cda0e3686"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
